{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "   ---------------------------------------- 0.0/250.0 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 20.5/250.0 kB 330.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 225.3/250.0 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 250.0/250.0 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C://Users//Jamie Humphries//OneDrive - ionscout.com//biased_Datasurvey_data2.xlsx'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(30)\n",
    "# Define the number of responses to generate\n",
    "num_responses = 2000\n",
    "\n",
    "satisfaction = np.random.randint(4, 8, num_responses)\n",
    "\n",
    "# Define the multiplier to strengthen the bias\n",
    "bias_multiplier = 5000000000000\n",
    "\n",
    "# Create biases by adding a scaled version of satisfaction to a smaller noise component\n",
    "survey_df['recommend'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 5, 7).astype(int)\n",
    "survey_df['repurchase'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 4, 7).astype(int)\n",
    "survey_df['return'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "survey_df['staff'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "survey_df['checkout'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "\n",
    "# Introduce bias to 'recommend', 'repurchase', 'return', 'staff', and 'checkout' based on 'satisfaction'\n",
    "# The noise is normally distributed around 0, with a standard deviation of 0.5\n",
    "noise_std =0.5\n",
    "noise = np.random.normal(0, noise_std, num_responses)\n",
    "\n",
    "# Define the range for the random values based on the provided example\n",
    "# It seems like the values range from 1 to 7 for the survey responses, \n",
    "# while other values such as age, obs, involve, actual_purchase and amount_purchase seem to have a different range.\n",
    "# For simplicity, I will keep them similar to the ones in the given example.\n",
    "\n",
    "# Create a DataFrame to hold the synthetic survey responses\n",
    "# Assuming the range for survey responses is 1-7 inclusive\n",
    "survey_columns = ['id', 'retailer', 'rcode', 'satisfaction', 'repurchase', 'recommend', 'checkout', \n",
    "                  'contact', 'merchandise', 'pricing', 'return', 'staff', 'store', 'return1', \n",
    "                  'return2', 'return3', 'return4', 'return5', 'return6', 'return7', 'return8', \n",
    "                  'return9', 'store1', 'store2', 'store3', 'store4', 'store5', 'store6', 'store7', \n",
    "                  'store8', 'store9', 'store10', 'checkout1', 'checkout2', 'checkout3', 'checkout4', \n",
    "                  'contact1', 'contact2', 'contact3', 'merchandise1', 'merchandise2', 'merchandise3', \n",
    "                  'merchandise4', 'merchandise5', 'pricing1', 'pricing2', 'pricing3', 'pricing4', \n",
    "                  'pricing5', 'pricing6', 'pricing7', 'staff1', 'staff2', 'staff3', 'staff4', 'staff5', \n",
    "                  'female', 'obs', 'age', 'involve', 'actual_purchase', 'amount_purchase']\n",
    "\n",
    "# Define bounds for columns based on the observed data from the example\n",
    "response_bounds = {\n",
    "    'id': (1, num_responses), # Assuming ID should be unique\n",
    "    'retailer': ['Gallery Furniture', 'Star Furniture', 'Ashley Furniture HomeStore'], # Assuming these are the only options\n",
    "    'rcode': (1, 3), # Assuming these are the only codes observed\n",
    "    'satisfaction': (4, 7),\n",
    "    'repurchase': (5, 6),\n",
    "    'recommend': (3, 6),\n",
    "    'checkout': (3, 6),\n",
    "    'staff': (3, 6),\n",
    "    'return': (3, 7), # Assuming this is a general return rating\n",
    "    # ... Similar for all other survey response columns\n",
    "    'female': (0, 1), # Assuming 0 and 1 are the only options for gender\n",
    "    'obs': (1, 300), # Based on the max observed in the example\n",
    "    'age': (18, 50), # Assuming an age range based on the example\n",
    "    'involve': (1, 7), # Assuming this is similar to other responses\n",
    "    'actual_purchase': (0, 1), # Assuming this is a binary response\n",
    "    'amount_purchase': (0, 6000) # Assuming based on the max observed\n",
    "}\n",
    "# Introduce bias to 'recommend', 'repurchase', 'return', 'staff', and 'checkout' based on 'satisfaction'\n",
    "# The noise is normally distributed around 0, with a standard deviation of 1\n",
    "noise = np.random.normal(0, 1, num_responses)\n",
    "\n",
    "\n",
    "\n",
    "# Average 'satisfaction' with 'return', 'staff', and 'checkout' to create an overall 'satisfaction' score\n",
    "# This will increase the influence of 'return', 'staff', and 'checkout' on 'satisfaction'\n",
    "satisfaction = np.round((satisfaction + return_scores + staff_scores + checkout_scores) / 4).astype(int)\n",
    "\n",
    "# Ensure the 'id' column is unique and sequential\n",
    "survey_df['id'] = np.arange(1, num_responses + 1)\n",
    "\n",
    "# Shuffle the DataFrame to remove any unintended order biases\n",
    "survey_df = survey_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Generating random data for the survey responses\n",
    "# For simplicity, let's assume uniform distribution for all responses\n",
    "survey_data = {\n",
    "    col: (\n",
    "        np.random.choice(response_bounds[col], num_responses) if isinstance(response_bounds[col], list)\n",
    "        else np.random.randint(response_bounds[col][0], response_bounds[col][1]+1, num_responses)\n",
    "    )\n",
    "    for col in survey_columns if col in response_bounds\n",
    "}\n",
    "\n",
    "# Ensure the 'id' column is unique and sequential\n",
    "survey_data['id'] = np.arange(1, num_responses + 1)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "survey_df = pd.DataFrame(survey_data)\n",
    "# Create biases by adding a scaled version of satisfaction to a smaller noise component\n",
    "survey_df['recommend'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 2) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "survey_df['repurchase'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 2) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "survey_df['return'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "survey_df['staff'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "survey_df['checkout'] = np.clip(satisfaction + bias_multiplier * (satisfaction - 4) + np.random.normal(0, noise_std, num_responses), 1, 7).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Check the first few rows of the generated DataFrame\n",
    "survey_df.head()\n",
    "\n",
    "# Generating random data for all survey response columns, including those not listed in response_bounds\n",
    "# For the missing columns which are likely survey questions, we will assume a range of 1-7 as well\n",
    "survey_data_complete = {\n",
    "    col: (\n",
    "        np.random.choice(response_bounds[col], num_responses) if isinstance(response_bounds[col], list)\n",
    "        else np.random.randint(response_bounds[col][0], response_bounds[col][1]+1, num_responses)\n",
    "    ) if col in response_bounds else np.random.randint(1, 8, num_responses)\n",
    "    for col in survey_columns\n",
    "}\n",
    "\n",
    "# Ensure the 'id' column is unique and sequential\n",
    "survey_data_complete['id'] = np.arange(1, num_responses + 1)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "survey_df_complete = pd.DataFrame(survey_data_complete)\n",
    "\n",
    "# Now we'll save this DataFrame to an Excel file\n",
    "excel_path = 'C://Users//Jamie Humphries//OneDrive - ionscout.com//biased_Datasurvey_data2.xlsx'\n",
    "survey_df_complete.to_excel(excel_path, index=False)\n",
    "\n",
    "# Return the path to the saved Excel file\n",
    "excel_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
