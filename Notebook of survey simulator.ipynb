{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the number of responses and the seed values for random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set the number of respondents\n",
    "n_respondents = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the demographic and other responses \n",
    "#### All are randomly assigned with a biased or normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Satisfaction scores\n",
    "satisfaction = np.random.uniform(low=1, high=7, size=n_respondents)\n",
    "\n",
    "# Observation ID (assuming sequential starting from 1)\n",
    "# This is the only variable that is not generated randomly\n",
    "# This is the also the respondent ID\n",
    "obs_id = np.arange(1, n_respondents + 1)\n",
    "\n",
    "# Gender (0 for male, 1 for female, assuming roughly 50/50 distribution)\n",
    "# This is a binary variable\n",
    "# By changing the probability, you can change the distribution\n",
    "# The first argument is the number of trials, the second is the probability\n",
    "gender = np.random.binomial(1, 0.5, n_respondents)\n",
    "\n",
    "# Age (Uniformly distributed between 18 and 70)\n",
    "age = np.random.randint(18, 71, n_respondents)\n",
    "\n",
    "# Involvement Level (1 to 5 scale)\n",
    "involvement = np.random.randint(1, 6, n_respondents)\n",
    "\n",
    "# Actual Purchase (binary, assuming 70% probability of purchase)\n",
    "# This is a binary variable\n",
    "# By changing the probability, you can change the distribution\n",
    "# The first argument is the number of trials, the second is the probability\n",
    "actual_purchase = np.random.binomial(1, 0.7, n_respondents)\n",
    "\n",
    "# Amount of Purchase ($0 to $2000, only for those who made a purchase)\n",
    "amount_purchase = actual_purchase * np.random.uniform(0, 2000, n_respondents)\n",
    "\n",
    "# Education Level (1 to 4 scale)\n",
    "# 1: High School, 2: Bachelors, 3: Masters, 4: PhD\n",
    "# This is an ordinal variable\n",
    "# By changing the range, you can change the distribution\n",
    "# The first argument is the lowest value, the second is the highest value\n",
    "education_level = np.random.randint(1, 5, n_respondents)\n",
    "\n",
    "# Income (divided into 5 brackets)\n",
    "# This is a categorical variable\n",
    "# By changing the brackets, you can change the distribution\n",
    "# The first argument is the list of values to choose from\n",
    "# The choice is made in a normalized way, so you can use any list of values\n",
    "income_brackets = ['0-25k', '25k-50k', '50k-75k', '75k-100k', '100k+']\n",
    "income = np.random.choice(income_brackets, n_respondents)\n",
    "\n",
    "# Compile additional demographics into the DataFrame\n",
    "# This is the creation of the demographic dataframe\n",
    "# The data will be added to the final dataframe before saving\n",
    "# This is a separate dataframe to keep the code clean\n",
    "# To make changes to the demographics, you only need to change this code\n",
    "# ensure that changes  have a corresponding varible assignment like the examples above and listed below\n",
    "additional_demo_df = pd.DataFrame({\n",
    "    'Obs': obs_id,\n",
    "    'Female': gender,\n",
    "    'Age': age,\n",
    "    'Involve': involvement,\n",
    "    'Actual_Purchase': actual_purchase,\n",
    "    'Amount_Purchase': amount_purchase,\n",
    "    'Education_Level': education_level,\n",
    "    'Income_Bracket': income\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the varibles for the first level response\n",
    "##### In this example we have Recommend and Repurchase that are influence by Satisfaction\n",
    "##### We have Return, Staff, Contact, Price, Store, Checkout and Merchandise that influences Satisfaction\n",
    "##### Here you can adjust which varibles influence the next level and assign biased varible data\n",
    "##### to simulate significanct parameter estimates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate dependent variables with targeted relationships\n",
    "# This function will be used to generate dependent variables\n",
    "# The function takes in the independent variable, a coefficient, and a noise level\n",
    "# The function returns the dependent variable\n",
    "# The function also clips the scores to the specified range\n",
    "\n",
    "def generate_dependent_variable(satisfaction, coefficient, noise_std, scale=(1, 7)):\n",
    "    noise = np.random.normal(0, noise_std, n_respondents)\n",
    "    variable_scores = satisfaction * coefficient + noise\n",
    "    return np.clip(variable_scores, scale[0], scale[1])\n",
    "\n",
    "# Generating Recommend and Repurchase scores with specific influences from Satisfaction\n",
    "# This is the creation of the dependent variables\n",
    "# The data will be added to the final dataframe before saving\n",
    "# This is a separate dataframe to keep the code clean\n",
    "# To make changes to the dependent variables, you only need to change this code\n",
    "# ensure that changes  have a corresponding varible assignment like the examples above and listed below\n",
    "# You can make changes to the coefficients and noise levels to see the impact on the dependent variables\n",
    "# You can make changes to the names of the dependent varibles to suit your needs\n",
    "# the settings following satisfaction are the coefficients and noise levels\n",
    "#\n",
    "recommend = generate_dependent_variable(satisfaction, 0.7, 0.8)\n",
    "repurchase = generate_dependent_variable(satisfaction, 1.1, 0.5)\n",
    "\n",
    "# Continue generating other variables as before\n",
    "# This is the creation of the independent varibles to Overall Satisfaction\n",
    "# The data will be added to the final dataframe before saving\n",
    "# This is a separate dataframe to keep the code clean\n",
    "# To make changes to the independent variables, you only need to change this code\n",
    "# ensure that changes  have a corresponding varible assignment like the examples above and listed below\n",
    "# You can make changes to the coefficients and noise levels to see the impact on the dependent variables\n",
    "# You can simply add more variables to the list to create more independent variables\n",
    "# the settings following satisfaction are the coefficients and noise levels\n",
    "# You can move the names around to the biased varibles and the unbiased varibles to simulate new data and its impact\n",
    "# This allows you to create many different datasets with different relationships between the independent and dependent variables\n",
    "# The names of the independent variables can be changed to suit your needs\n",
    "\n",
    "return_scores = generate_dependent_variable(satisfaction, 0.3, 1.0)\n",
    "staff_scores = generate_dependent_variable(satisfaction, 0.4, 1.0)\n",
    "contact_scores = generate_dependent_variable(satisfaction, 0.4, 1.0)\n",
    "price_scores = np.random.uniform(1, 7, n_respondents)\n",
    "store_scores = np.random.uniform(1, 7, n_respondents)\n",
    "checkout_scores = np.random.uniform(1, 7, n_respondents)\n",
    "merchandise_scores = np.random.uniform(1, 7, n_respondents)\n",
    "\n",
    "# Compile the dataset\n",
    "# Ensure that the names of the independent and dependent variables match the names of the variables above\n",
    "df = pd.DataFrame({\n",
    "    'Satisfaction': satisfaction,\n",
    "    'Recommend': recommend,\n",
    "    'Repurchase': repurchase,\n",
    "    'Return': return_scores,\n",
    "    'Staff': staff_scores,\n",
    "    'Contact': contact_scores,\n",
    "    'Price': price_scores,\n",
    "    'Store': store_scores,\n",
    "    'Checkout': checkout_scores,\n",
    "    'Merchandise': merchandise_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create third order of varibles\n",
    "#### These Varibles influence the specific section satisfation scores which influence satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to generate questions results that in a survey\n",
    "# would be spe4cific to the independent variables that influence the varibles that inturn influence satisfaction\n",
    "# The function takes in the independent variable, a coefficient, and a noise level\n",
    "# the target_qs is a list of the questions that are targeted to be biased and have higher parameter estimates\n",
    "\n",
    "def generate_questions_improved(main_variable, num_questions=6, target_qs=[2, 3, 5]):\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    questions = {}\n",
    "    main_variable_flat = main_variable.flatten()  # Ensure main_variable is flat\n",
    "\n",
    "    for q in range(1, num_questions + 1):\n",
    "        # Define initial noise variance based on whether the question is targeted\n",
    "        noise_variance = 0.5 if q in target_qs else 1  # Lower variance for targeted questions\n",
    "        \n",
    "        # Generate noise and question scores\n",
    "        noise = np.random.normal(0, noise_variance, size=n_respondents)\n",
    "        q_scores = 0.5 * main_variable_flat + noise  # Simplified linear relationship + noise\n",
    "        q_scores = np.clip(q_scores, 1, 7)  # Ensure scores are within 1 to 7\n",
    "        \n",
    "        questions[f'Q{q}'] = q_scores\n",
    "\n",
    "    return pd.DataFrame(questions)\n",
    "\n",
    "    # Generate main variables\n",
    "# Assuming `generate_dependent_variable` has been used for 'Return', 'Staff', 'Contact'\n",
    "\n",
    "# Generate questions for each main variable and add to df\n",
    "# you can chage the name and number of the main variables to suit your needs\n",
    "# six question results are generated for each main variable\n",
    "# the target_qs list is used to specify which questions are biased\n",
    "# the number of the targets are counted left to right starting from 1\n",
    "main_variables = ['Return', 'Staff', 'Contact', 'Price', 'Store', 'Checkout', 'Merchandise']\n",
    "for var in main_variables:\n",
    "    qs_df = generate_questions_improved(df[var].values.reshape(-1, 1), num_questions=6, target_qs=[2, 3, 5])\n",
    "    # Brings together the main variables and the questions results\n",
    "    df = pd.concat([df, qs_df.add_prefix(f'{var}_')], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brings everything together and saves the file to the directory of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the demographic data to the full dataset\n",
    "full_df = pd.concat([df, additional_demo_df], axis=1)\n",
    "try:\n",
    "    # File path (Adjust based on your local file system when running locally)\n",
    "    file_path = \"C://Users//Jamie Humphries//OneDrive - ionscout.com//biased_Datasurvey_data2.xlsx\"\n",
    "    full_df.to_excel(file_path, index=False)\n",
    "    # Print the success message\n",
    "    print(\"The full dataset file has been created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Print the error message if there's an error\n",
    "    print(\"An error occurred:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
